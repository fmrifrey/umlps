{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from mirtorch.linear import NuSense, NuSenseGram, Diff3dgram, Diag\n",
    "from mirtorch.alg.cg import CG\n",
    "import os\n",
    "import sys\n",
    "from recutl import mri_coil_compress, resize_nd\n",
    "from vis3d import tim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "gpu_idx = 2 # GPU index for CUDA (-1 = CPU)\n",
    "fname_kdata = '/home/djfrey/data/lps_fmri_20250411/lps_test/lps.h5' # name of the GRE data file\n",
    "fname_smaps = os.path.join(os.path.dirname(fname_kdata), '../smaps.h5') # name of the smaps file\n",
    "ncoil_comp = 16 # number of virtual coils to compress to\n",
    "cutoff = 0.85 # kspace cutoff for echo-in/out filtering\n",
    "rolloff = 0.2 # kspace rolloff for echo-in/out filtering\n",
    "lam = 0.15 # regularization parameter for quadratic differencing penalty\n",
    "niter = 50 # number of iterations for CG\n",
    "M = None # reconstructed matrix size (None = N*cutoff)\n",
    "ints2use = None # interleaf indices to use (None = all)\n",
    "prjs2use = None # projection indices to use (None = all)\n",
    "reps2use = 1 # repetition indices to use (None = all)\n",
    "volwidth = None # number of projections per volume (None = use each rep as a volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "# select device\n",
    "if torch.cuda.is_available() & (gpu_idx >= 0):\n",
    "    device0 = torch.device(f'cuda:{gpu_idx}')\n",
    "else:\n",
    "    device0 = torch.device('cpu')\n",
    "print(f'using device: {device0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "with h5py.File(fname_kdata, 'r') as h5_file:\n",
    "    kdata = h5_file['kdata/real'][:] + 1j * h5_file['kdata/imag'][:] # kspace data\n",
    "    k_in = h5_file['ktraj/spoke_in'][:] # kspace spoke-in trajectory (1/cm)\n",
    "    k_out = h5_file['ktraj/spoke_out'][:] # kspace spoke-out trajectory (1/cm)\n",
    "    fov = h5_file['seq_args/fov'][0][0] # field of view (cm)\n",
    "    N = int(h5_file['seq_args/N'][0][0]) # 3D matrix size\n",
    "    nseg = int(h5_file['seq_args/nseg'][0][0]) # number of points per segment\n",
    "    nspokes = int(h5_file['seq_args/nspokes'][0][0]) # number of spokes\n",
    "    nprj = int(h5_file['seq_args/nprj'][0][0]) # number of projections\n",
    "    nint = int(h5_file['seq_args/nint'][0][0]) # number of interleaves\n",
    "    nrep = int(h5_file['seq_args/nrep'][0][0]) # number of repetitions\n",
    "    ncoil = int(h5_file['ncoil'][0][0]) # number of coils\n",
    "\n",
    "# convert to tensors\n",
    "kdata = torch.tensor(kdata).reshape(ncoil,nrep,nprj,nint,nseg*nspokes)\n",
    "k_in = torch.tensor(k_in).reshape(3,nrep,nprj,nint,nseg*nspokes)\n",
    "k_out = torch.tensor(k_out).reshape(3,nrep,nprj,nint,nseg*nspokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default values for interleaves, projections, and repetitions to use\n",
    "if ints2use is None:\n",
    "    ints2use = nint\n",
    "if prjs2use is None:\n",
    "    prjs2use = nprj\n",
    "if reps2use is None:\n",
    "    reps2use = nrep\n",
    "if volwidth is None:\n",
    "    volwidth = prjs2use*ints2use\n",
    "\n",
    "# get number of volumes\n",
    "nvol = reps2use*prjs2use*ints2use // volwidth\n",
    "\n",
    "# arrange data into volumes\n",
    "kdata2 = kdata.clone()\n",
    "kdata2 = kdata2[:,np.arange(reps2use),:,:,:]\n",
    "kdata2 = kdata2[:,:,np.arange(prjs2use),:,:]\n",
    "kdata2 = kdata2[:,:,:,np.arange(ints2use),:]\n",
    "kdata2 = kdata2.reshape(ncoil,reps2use*prjs2use*ints2use,nseg*nspokes)\n",
    "kdata2 = kdata2[:,:nvol*volwidth,:]\n",
    "kdata2 = kdata2.reshape(ncoil,nvol,volwidth*nseg*nspokes)\n",
    "kdata2 = kdata2.permute(1,0,2)\n",
    "\n",
    "# arrange kspace trajectory into volumes\n",
    "k_in2 = k_in.clone()\n",
    "k_in2 = k_in2[:,np.arange(reps2use),:,:,:]\n",
    "k_in2 = k_in2[:,:,np.arange(prjs2use),:,:]\n",
    "k_in2 = k_in2[:,:,:,np.arange(ints2use),:]\n",
    "k_in2 = k_in2.reshape(3,reps2use*prjs2use*ints2use,nseg*nspokes)\n",
    "k_in2 = k_in2[:,:nvol*volwidth,:]\n",
    "k_in2 = k_in2.reshape(3,nvol,volwidth*nseg*nspokes)\n",
    "k_in2 = k_in2.permute(1,0,2)\n",
    "\n",
    "k_out2 = k_out.clone()\n",
    "k_out2 = k_out2[:,np.arange(reps2use),:,:,:]\n",
    "k_out2 = k_out2[:,:,np.arange(prjs2use),:,:]\n",
    "k_out2 = k_out2[:,:,:,np.arange(ints2use),:]\n",
    "k_out2 = k_out2.reshape(3,reps2use*prjs2use*ints2use,nseg*nspokes)\n",
    "k_out2 = k_out2[:,:nvol*volwidth,:]\n",
    "k_out2 = k_out2.reshape(3,nvol,volwidth*nseg*nspokes)\n",
    "k_out2 = k_out2.permute(1,0,2)\n",
    "\n",
    "# calculate reconstructed matrix size\n",
    "if M is None:\n",
    "    M = int(np.ceil(N*cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(fname_smaps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m h5_file:\n\u001b[1;32m      3\u001b[0m     smaps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(h5_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/real\u001b[39m\u001b[38;5;124m'\u001b[39m][:] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m h5_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/imag\u001b[39m\u001b[38;5;124m'\u001b[39m][:])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(kdata) \u001b[38;5;66;03m# kspace data\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m smaps \u001b[38;5;241m=\u001b[39m resize_nd(smaps, (\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m), M\u001b[38;5;241m/\u001b[39msmaps\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;66;03m# resize to match kspace data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m smaps \u001b[38;5;241m=\u001b[39m smaps\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "# load in the sensitivity maps\n",
    "with h5py.File(fname_smaps, 'r') as h5_file:\n",
    "    smaps = torch.tensor(h5_file['/real'][:] + 1j * h5_file['/imag'][:]).unsqueeze(0).to(kdata) # kspace data\n",
    "smaps = resize_nd(smaps, (2,3,4), M/smaps.shape[2]) # resize to match kspace data\n",
    "smaps = smaps.permute(0,1,4,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coil compress the data\n",
    "kdata_comp,Vr = mri_coil_compress(kdata2, ncoil=ncoil_comp)\n",
    "\n",
    "# coil compress the sensitivity maps\n",
    "smaps_comp,_ = mri_coil_compress(smaps, Vr=Vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert trajectory to spatial frequencies\n",
    "om_in = 2*torch.pi * fov/M * k_in2\n",
    "om_out = 2*torch.pi * fov/M * k_out2\n",
    "\n",
    "# create filter objects\n",
    "r_cut = cutoff * N/M * torch.pi\n",
    "r_roll = rolloff * N/M * torch.pi\n",
    "kfilt = lambda r: (r <= r_cut) * 1/(1 + torch.exp(2*torch.pi * (r - r_cut)/r_roll))\n",
    "Hvec_in = kfilt(torch.norm(om_in,2,dim=1,keepdim=True)).repeat(1,ncoil_comp,1)\n",
    "Hvec_out = kfilt(torch.norm(om_out,2,dim=1,keepdim=True)).repeat(1,ncoil_comp,1)\n",
    "H_in = Diag(Hvec_in.to(device0))\n",
    "H_out = Diag(Hvec_out.to(device0))\n",
    "\n",
    "# create nufft system operators with flat sensitivity\n",
    "FS_in = NuSense(smaps_comp.to(device0), om_in.to(device0), nbatch=nvol)\n",
    "FS_out = NuSense(smaps_comp.to(device0), om_out.to(device0), nbatch=nvol)\n",
    "\n",
    "# set up system matrices and data\n",
    "A = H_in*FS_in + H_out*FS_out\n",
    "G_in = NuSenseGram(smaps_comp.to(device0), om_in.to(device0), kweights=Hvec_in.to(device0), nbatch=nvol)\n",
    "G_out = NuSenseGram(smaps_comp.to(device0), om_out.to(device0), kweights=Hvec_out.to(device0), nbatch=nvol)\n",
    "AHA = G_in + G_out + 2*(H_in*FS_in).H*(H_out*FS_out)\n",
    "\n",
    "# add L2 roughness penalty\n",
    "THT = Diff3dgram(FS_in.size_in)\n",
    "AHA_tikh = AHA + lam*THT\n",
    "\n",
    "# set up data\n",
    "y = kdata_comp.to(device0)\n",
    "AHy = A.H * y\n",
    "\n",
    "# set up the CG solver\n",
    "solv = CG(AHA_tikh, max_iter=niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve with CG\n",
    "x = solv.run(torch.zeros(nvol,1,M,M,M).to(kdata).to(device0), AHy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'Nz' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     autoreload\u001b[38;5;241m.\u001b[39mreload(autoreload)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvis3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tim\n\u001b[0;32m----> 7\u001b[0m tim(x)\n\u001b[1;32m      8\u001b[0m tim(x,viewtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmid3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/code/projects/umlps/recon_pytorch/vis3d.py:30\u001b[0m, in \u001b[0;36mtim\u001b[0;34m(img, viewtype, rows, cols, offset)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# get image size\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     Nx,Ny \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m     31\u001b[0m     Nz \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     32\u001b[0m     Nbatch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(img\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'Nz' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# visualize the results\n",
    "from vis3d import tim\n",
    "tim(x)\n",
    "tim(x,viewtype='mid3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umlps_recon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
